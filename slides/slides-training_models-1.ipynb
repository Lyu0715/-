{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 4장 모델 훈련 (1부)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 주요 내용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **선형 회귀**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **경사하강법**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **비선형 데이터 학습: 다항 회귀**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 학습 곡선"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 모델 규제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 로지스틱 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cu97Fkqb1JRm",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4.1. 선형 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 선형 회귀의 중요성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫째, 선형 회귀 모델의 훈련 과정이 매우 단순하여 머신러닝의 기초 개념을 설명하는 데에 매우 유용함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "둘째, 딥러닝 심층 신경망 모델 등 대다수의 머신러닝 모델이 훈련 과정에서 선형 회귀 모델의 훈련 방식을 활용하면서 보다 복잡한 문제들을 해결함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cu97Fkqb1JRm",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4.1.1. 머신러닝 모델이란?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 예제: 1인당 GDP와 삶의 만족도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cu97Fkqb1JRm",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "$$(\\text{삶의만족도}) = \\theta_0 + (\\text{1인당GDP}) \\cdot \\theta_1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "또는"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat y = \\theta_0 + x_1 \\cdot \\theta_1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 예제: 캘리포니아 주택 가격 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cu97Fkqb1JRm",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* $\\hat y$: 예측된 주택 중위 가격\n",
    "* $x_i$: 구역의 $i$ 번째 특성값(위도, 경도, 중간소득, 가구당 인원 등)\n",
    "* $\\theta_0$: 편향\n",
    "* $\\theta_i$: $i$ 번째 특성에 대한 가중치. 단, $1 \\le i \\le 24$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cu97Fkqb1JRm",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "$$\\hat y = \\theta_0 + x_1 \\cdot \\theta_1 + \\cdots + x_{24} \\cdot \\theta_{24}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 선형 회귀 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat y = \\theta_0 + x_1 \\cdot \\theta_1 + \\cdots + x_n \\cdot \\theta_{n}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/perceptron.png\" width=\"350\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 파라미터, 편향, 가중치"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **파라미터**<font size=\"2\">parameter</font>: $\\theta_0$, $\\theta_1$, ..., $\\theta_{n}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 파라미터는 모델이 훈련을 통해 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\theta_0$: **편향**<font size=\"2\">bias</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 나머지 파라미터: **가중치**<font size=\"2\">weight</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4.1.2. 행렬 연산 표기법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/perceptron.png\" width=\"350\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cu97Fkqb1JRm",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "$$\n",
    "\\hat y\n",
    "= 1\\cdot \\theta_0 + x_1 \\cdot \\theta_1 + \\cdots + x_n \\cdot \\theta_{n}\n",
    "= [1, x_1, \\dots, x_n]\\, \n",
    "\\begin{bmatrix}\n",
    "\\theta_0\\\\\n",
    "\\theta_1 \\\\\n",
    "\\vdots \\\\\n",
    "\\theta_n\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `LinearRegression` 모델의 예측값 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 머신러닝 모델은 일반적으로 여러 개의 입력값에 대해 동시에 예측값 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{\\mathbf y} = \n",
    "\\begin{bmatrix}\n",
    "\\hat y_0 \\\\\n",
    "\\vdots \\\\\n",
    "\\hat y_{m-1}\n",
    "\\end{bmatrix}\n",
    "= \n",
    "\\begin{bmatrix} \n",
    "1, x_1^{(0)}, \\,\\,\\,\\,\\dots\\,\\,\\,\\,\\,\\, , x_n^{(0)} \\\\\n",
    "\\vdots \\\\\n",
    "1, x_1^{(m-1)}, \\dots, x_n^{(m-1)} \\\\\n",
    "\\end{bmatrix}\n",
    "\\,\\, \n",
    "\\begin{bmatrix}\n",
    "\\theta_0\\\\\n",
    "\\theta_1 \\\\\n",
    "\\vdots \\\\\n",
    "\\theta_n\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 간략하게 줄이면:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "$$\n",
    "\\hat{\\mathbf y} = \\mathbf{X}\\, \\mathbf{\\theta}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4.1.3. 머신러닝 모델 훈련의 목표"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 타깃에 최대한 가까운 예측값 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 즉, 모델의 예측 성능 최대화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델 훈련중에는 모델의 성능을 일반적으로 모델의 비용 함수를 이용하여 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 비용 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델의 성능이 얼마나 나쁜지 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델의 종류와 목표에 따라 다른 비용 함수 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 회귀 모델: 일반적으로 평균 제곱 오차(MSE)를 비용 함수로 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "$$\n",
    "\\mathrm{MSE}(\\theta) =\n",
    "\\frac 1 m \\sum_{i=1}^{m} \\big(\\mathbf{x}^{(i)}\\, \\mathbf{\\theta} - y^{(i)}\\big)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 모델 훈련의 최종 목표"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\mathrm{MSE}(\\theta)$ 가 최소가 되도록 하는 $\\theta$ 찾기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 선형 회귀의 경우 모델에 따라 다음 두 가지 방식 중 하나 이용\n",
    "\n",
    "    * 방식 1: 정규방정식 또는 특이값 분해(SVD)\n",
    "\n",
    "    * 방식 2: 경사하강법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 정규 방정식: `LinearRegression` 등 선형 회귀를 활용하는 극히 일부 모델에서, \n",
    "    그것도 훈련셋의 크기와 입력 특성수 모두 작을 때만 활용됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 경사하강법: 딥러닝 모델에서도 기본으로 활용되는 훈련 기법임. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3BbE04h8-tOu",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4.2. 경사하강법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 경사하강법 관련 주요 개념"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 하이퍼파라미터\n",
    "- 파라미터\n",
    "- 배치 크기\n",
    "- 비용 함수\n",
    "- 전역/지역 최소값\n",
    "- 스텝\n",
    "- 학습률\n",
    "- 에포크\n",
    "- 스텝 크기\n",
    "- 최적 학습 모델\n",
    "- 비용 함수의 그레이디언트 벡터\n",
    "- 허용 오차"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 하이퍼파라미터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 훈련시킬 모델을 지정할 때 사용되는 설정 옵션"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 즉 해당 클래스의 객체를 생성할 때 클래스의 생성자 함수에 전달되는 인자들."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 대표적으로 학습률, 에포크, 허용 오차, 배치 크기 등등"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3BbE04h8-tOu",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 파라미터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3BbE04h8-tOu",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 선형 회귀 모델에 사용되는 편향과 가중치 파라미터처럼 모델 훈련중에 학습되는 값들"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3BbE04h8-tOu",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 모델 훈련을 통해 학습된 파라미터는 훈련된 모델 객체의 속성으로 저장됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 배치 크기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 보다 좋은 파라미터 값으로 업데이트하기 위해 필요한 훈련 샘플의 수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 전체 데이터셋의 크기 $m$과 구분하기 위해 $m_b$로 표기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 파라미터 업데이트는 따라서 $m_b$ 개의 훈련셋을 학습할 때마다 이뤄짐."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 사이킷런 모델: 배치 크기 선택 옵션 지원 없으며 경사하강법을 적용하는 모든 모델의 배치 크기는 1임.\n",
    "    - `LinearRegression`: 경사하강법 사용하지 않음.\n",
    "    - `SGDRegressor`: $m_b = 1$\n",
    "    - `LogisticRegressor`: $m_b = 1$    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 딥러닝 심층 신경망 모델: 배치 크기 선택 옵션 제공. 일반적으로 8, 16, 32, 64, 128, 256 중에 하나 선택."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3BbE04h8-tOu",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 비용 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3BbE04h8-tOu",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 모델의 성능이 얼마나 나쁜가를 측정하는 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3BbE04h8-tOu",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 배치 단위로 비용 함숫값 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3BbE04h8-tOu",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 회귀 모델의 배치 단위로 계산되는 MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3BbE04h8-tOu",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "$$\n",
    "\\mathrm{MSE}(\\mathbf{\\theta}) = \n",
    "\\frac 1 {m_b} \\sum_{i=0}^{m_b-1} \\big(\\mathbf{x}^{(i)}\\, \\mathbf{\\theta} - y^{(i)}\\big)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3BbE04h8-tOu",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 전역/지역 최소값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3BbE04h8-tOu",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 비용 함수가 가질 수 있는 전역/지역 최소값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3BbE04h8-tOu",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 예제: 선형 회귀 모델의 평균 제곱 오차(MSE) 함수가 갖는 전역/지역 최소값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-04.png\" width=\"600\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 스텝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 배치 크기 $m_b$ 만큼의 샘플에 대해 예측값을 계산한 후에 비용 함수를 이용하여 성능을 평가한 후에 \n",
    "    비용 함수를 줄이는 방향으로 파라미터를 한 번 업데이트 하는 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/step.png\" width=\"400\"/></div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9vcJYAPEC0nA",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 학습률"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9vcJYAPEC0nA",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 훈련 스텝마다 비용 함숫값 계산에 사용되는 파라미터 $\\mathbf{\\theta}$를 얼만큼씩 조정할 것인지를 정하는 비율"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 에포크"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 훈련셋에 포함된 모든 데이터를 대상으로 예측값을 한 번 계산하는 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이 과정동안 실행된 스텝 회수만큼 파라미터의 업데이트가 이루어짐."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 스텝 크기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 에포크 동안 실행된 스텝의 횟수, 즉 파라미터를 조정한 횟수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{스텝 크기 = (훈련셋 크기) / (배치 크기)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 예를 들어, 훈련셋 크기가 1,000이고 배치 크기가 10이면 에포크마다 100번의 스텝 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3BbE04h8-tOu",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 최적 학습 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3BbE04h8-tOu",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 비용 함수를 최소화하는파라미터를 학습한 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3BbE04h8-tOu",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 최종적으로 훈련을 통해 얻고자 하는 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3BbE04h8-tOu",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 비용 함수의 그레이디언트 벡터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3BbE04h8-tOu",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 함수의 그레이디언트 벡터는 방향과 크기에 대한 정보 제공"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3BbE04h8-tOu",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 그레이디언트가 가리키는 방향의 **반대 방향**으로 움직여야 가장 빠르게 전역 최소값에 접근"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3BbE04h8-tOu",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- $\\textrm{MSE}(\\mathbf{\\theta})$ 함수의 $\\mathbf{\\mathbf{\\theta}}$ 에 대한 그레이디언트 벡터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3BbE04h8-tOu",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "$$\n",
    "\\nabla_\\theta \\textrm{MSE}(\\theta) =\n",
    "\\begin{bmatrix}\n",
    "    \\frac{\\partial}{\\partial \\theta_0} \\textrm{MSE}(\\theta) \\\\\n",
    "    \\frac{\\partial}{\\partial \\theta_1} \\textrm{MSE}(\\theta) \\\\\n",
    "    \\vdots \\\\\n",
    "    \\frac{\\partial}{\\partial \\theta_n} \\textrm{MSE}(\\theta)\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 허용 오차"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 비용 함수의 그레이디언트 벡터의 크기가 허용 오차보다 작아질 때 훈련 종료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 그레이디언트 벡터의 크기가 0에 가까우면 비용 함수의 전역 또는 지역 최소값에 거의 다다랐음을 의미하기 때문임."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4.2.1. 선형 회귀 모델 훈련과 경사하강법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE를 비용 함수로 사용하는 경우 경사하강법은 다음 과정으로 이루어짐."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\mathbf{\\theta}$를 임의의 값으로 지정한 후 훈련 시작"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\textrm{MSE}(\\theta)$ 가 허용 오차보다 적게 작아질 때까지 아래 과정 반복\n",
    "    * 배치 크기 $m_b$ 만큼의 훈련 샘플을 이용하여 예측값 생성 후 $\\mathrm{MSE}(\\mathbf{\\theta})$ 계산.\n",
    "    * 아래 점화식을 이용한 $\\theta$ 업데이트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\theta^{(\\text{new})} = \\theta^{(\\text{old})}\\, -\\, \\eta\\cdot \\nabla_\\theta \\textrm{MSE}(\\theta^{(\\text{old})})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 기울기 벡터의 방향과 크기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td style=\"padding:1px\">\n",
    "            <figure>\n",
    "                <img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/vector01.png\" style=\"width:70%\"/>\n",
    "            </figure>\n",
    "        </td>\n",
    "        <td style=\"padding:1px\">\n",
    "            <figure>\n",
    "                <img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/gradient01b.png\" style=\"width:100%\"/>\n",
    "            </figure>\n",
    "        </td>        \n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 그레이디언트 벡터의 방향과 크기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td style=\"padding:1px\">\n",
    "            <figure>\n",
    "                <img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/gd-1.png\" style=\"width:80%\" title=\"SGD without momentum\">\n",
    "                <figcaption>SGD optimization on loss surface contours</figcaption>\n",
    "            </figure>\n",
    "        </td>\n",
    "        <td style=\"padding:1px\">\n",
    "            <figure>\n",
    "                <img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/gd-2.png\" style=\"width:80%\" title=\"SGD without momentum\">\n",
    "                <figcaption>SGD optimization on saddle point</figcaption>\n",
    "            </figure>\n",
    "        </td>        \n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4.2.2. 학습률의 중요성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-01.png\" width=\"600\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9vcJYAPEC0nA",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 학습률이 너무 작은 경우: 비용 함수가 전역 최소값에 너무 느리게 수렴."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-02.png\" width=\"600\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9vcJYAPEC0nA",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 학습률이 너무 큰 경우: 비용 함수가 수렴하지 않음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-03.png\" width=\"600\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 학습율과 모델의 수렴 여부"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-04b.png\" width=\"700\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 비선형 모델 훈련의 어려움"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 선형 회귀 모델은 학습률을 적절하게 잡으면 언제나 최적의 모델로 수렴함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 반면에 비선형 모델은 학습률과 상관 없이 파라미터를 초기화하는 방식에 따라 지역 최소값에 수렴하거나 수렴하지 못하고 정체할 수도 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 대다수의 머신러닝 모델은 비선형 문제를 다룸."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-04.png\" width=\"600\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 특성 스케일링의 중요성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 왼편 그림: 두 특성의 스케일이 동일하게 조정된 경우비용 함수의 최소값으로 최단거리로 수렴함.\n",
    "     비용 등고선이 원 모양으로 그려지는 경우임."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 오른편 그림: 두 특성의 스케일이 다른 경우 비용 함수의 최소값으로 보다 먼 거리를 지나감.\n",
    "    비용 등고선이 타원 모양 또는 찌그러진 모양으로 그려지게 됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-04a.png\" width=\"600\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4.2.3. 경사하강법 종류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "**배치 경사하강법**\n",
    "\n",
    "* $m_b = m$\n",
    "* 주의: 여기서 사용되는 '배치'의 의미가 '배치 크기'의 '배치' 의미와 다름."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "**확률적 경사하강법**\n",
    "\n",
    "* $m_b = 1$\n",
    "* 하나의 훈련 샘플을 학습할 때마다 그레이디언트를 계산해서 파라미터 조정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "**미니배치 경사하강법**\n",
    "\n",
    "- $m_b \\in \\{ 2, 4, 6, 8, 16, 32, 64, 128, 256, 512, ..., \\}$\n",
    "- 사이킷런 모델은 미지원\n",
    "- 딥러닝 심층 신경망 모델은 배치 크기 선택 옵션 지원"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pEegSK8KMzhA",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 배치 경사하강법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 에포크마다 한 번 그레이디언트를 계산하여 파라미터 조정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 단점\n",
    "\n",
    "    * 훈련 세트가 크면 그레이디언트를 계산하는 데에 많은 시간 필요\n",
    "    * 아주 많은 데이터를 저장해야 하는 메모리 문제도 발생 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 사이킷런 모델을 포함하여 일반적으로 사용되지 않음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ywTb5DJhPwJD",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 확률적 경사하강법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ywTb5DJhPwJD",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 매우 큰 훈련 세트를 다룰 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ywTb5DJhPwJD",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 학습 과정이 매우 빠르며 파라미터 조정이 불안정 할 수 있기 때문에 지역 최소값에 상대적으로 덜 민감함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ywTb5DJhPwJD",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 단점: 학습 과정에서 파라미터의 동요가 심해서 경우에 따라 전역 최소값에 수렴하지 못하고 계속해서 발산할 가능성도 높음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ywTb5DJhPwJD",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-04c.png\" width=\"400\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "50b_hRZTRMW6",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 학습 스케줄"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "50b_hRZTRMW6",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 요동치는 파라미터를 제어하기 위해 학습률을 학습 과정 동안 천천히 줄어들게 만들 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "50b_hRZTRMW6",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 주의사항\n",
    "    * 학습률이 너무 빨리 줄어들면, 지역 최소값에 갇힐 수 있음\n",
    "    * 학습률이 너무 느리게 줄어들면 전역 최소값에 제대로 수렴하지 못하고 맴돌 수 있음\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "50b_hRZTRMW6",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 학습 스케줄(learning schedule): 훈련이 지속될 수록 학습률을 조금씩 줄이는 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 일반적으로 훈련 에포크가 진행될 수록 학습률이 조금씩 작아지도록 지정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oVXwxMY-SimN",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `SGDRegressor` 모델 선언 예제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oVXwxMY-SimN",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* `penalty=l2`: 규제 종류. `None`은 규제 미사용 없음 (추후 설명)\n",
    "* `max_iter=1000`: 최대 에포크 수\n",
    "* `tol=1e-3`: 허용 오차. `loss > best_loss - tol`이 `n_iter_no_change` 만큼의 에포크 동안 유지될 때 훈련 중지.\n",
    "* `eta0=0.01`: 초기 학습률. 학습 스케줄에 활용됨\n",
    "* `n_iter_no_change=5`: 지정된 에포크 동안 `loss > best_loss - tol` 상태가 유지되면 훈련 중지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "SGDRegressor(penalty=l2, \n",
    "             max_iter=1000, \n",
    "             tol=1e-3, \n",
    "             eta0=0.01,\n",
    "             n_iter_no_change=5, \n",
    "             random_state=42\n",
    "            )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JuFhsxFZTzvi",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 미니배치 경사하강법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JuFhsxFZTzvi",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 장점\n",
    "\n",
    "    * 배치 크기를 어느 정도 크게 하면 확률적 경사하강법(SGD) 보다 파라미터의 움직임이 덜 불규칙적이 됨\n",
    "    * 반면에 배치 경사하강법보다 빠르게 학습\n",
    "    * 학습 스케줄 잘 활용하면 최소값에 수렴함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JuFhsxFZTzvi",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 단점: SGD에 비해 지역 최소값에 수렴할 위험도가 보다 커짐."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 대부분의 딥러닝 심층 신경망 모델에서 지원됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6IvmA4ZvU3EJ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 세 경사하강법 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-05.png\" width=\"600\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wni6v8aeWSI9",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4.3. 비선형 데이터 학습: 다항 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wni6v8aeWSI9",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 다항 회귀(polynomial regression): 선형 회귀를 이용하여 비선형 데이터를 학습하는 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 선형 회귀: 1차 선형 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "$$\\hat y = \\theta_0 + \\theta_1\\, x_1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-06.png\" width=\"600\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2차 다항 회귀: 2차 다항식 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "$$\\hat y = \\theta_0 + \\theta_1\\, x_1 + \\theta_2\\, x_1^{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-07.png\" width=\"600\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XC9ZZdvUXjkH",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 사이킷런의 `PolynomialFeatures` 변환기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XC9ZZdvUXjkH",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 주어진 특성들의 거듭제곱과 특성들 사이의 곱셈을 실행하여 특성을 추가하는 기능 제공\n",
    "\n",
    "    ```python\n",
    "    PolynomialFeatures(degree=d)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XC9ZZdvUXjkH",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* `degree=d`: 몇 차 다항식을 활용할지 지정하는 하이퍼파라미터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XC9ZZdvUXjkH",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 예제: $n=2, d=2$인 경우에 $(x_1+x_2+x_3)^2$의 항목에 해당하는 3 개 특성 추가\n",
    "\n",
    "$$\n",
    "\\hat y = \n",
    "\\theta_0 + \\theta_1\\, x_1 + \\theta_2\\, x_2\n",
    "+ \\theta_3\\, x_{1} x_2\n",
    "+ \\theta_4\\, x_{1}^2 + \\theta_5\\, x_{2}^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 다항 회귀의 단점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 몇차 다항 회귀를 사용해야 할지 일반적으로 알 수 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 심층 신경망처럼 비선형 데이터를 분석하는 보다 좋은 모델이 개발되어 굳이 다항 회귀를 사용할 필요 없음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 여기서는 다만 비선형 데이터 분석을 선형 회귀 모델로 제대로 예측할 수 없을 보여주기 위해 언급되었음."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [],
   "name": "핸즈온머신러닝_4장.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
