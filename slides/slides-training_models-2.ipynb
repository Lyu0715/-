{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 4장 모델 훈련 (2부)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mt1fZDkqcCSM",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4.4. 학습 곡선"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 과소적합/과대적합 판정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 예제: 선형 모델, 2차 다항 회귀 모델, 300차 다항 회귀 모델 비교\n",
    "* 차수에 따라 모델이 훈련셋에 과소 또는 과대 적합할 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-08.png\" width=\"400\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 모델 성능 평가: 교차 검증 vs. 학습 곡선"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 성능 평가는 보통 다음 두 가지 방식을 따른다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 교차 검증(2장 참고)\n",
    "    * 과소적합: 훈련 점수와 교차 검증 점수 모두 낮은 경우\n",
    "    * 과대적합: 훈련 점수는 높지만 교차 검증 점수가 상대적으로 많이 낮은 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 학습 곡선<font size='2'>learning curve</font>\n",
    "    * 훈련셋와 검증셋에 대한 모델 성능을 비교하는 그래프\n",
    "        - x-축: 훈련셋 크기. 훈련셋의 크기를 1%에서부터 출발해서 점차 키워 나가면서 모델 성능 평가\n",
    "        - y-축: 훈련셋 크기에 따른 모델 성능. 훈련 점수와 검증 점수 사용\n",
    "    * 학습 곡선의 모양에 따라 과소적합/과대적합 판정 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kWg4z3s7f_Iu",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 과소적합 모델의 학습 곡선 특징"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2차 다항 함수의 분포를 따르는 데이터셋에 `LinearRegression` 모델을 적용한 학습 곡선\n",
    "    * 훈련셋에 대한 성능(빨강): 훈련셋이 커지면서 RMSE(평균 제곱근 오차)가 커지면서 어느 순간 변화 없음\n",
    "    * 검증셋에 대한 성능(파랑): 검증셋에 대한 성능이 훈련셋에 대한 성능과 거의 비슷해짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-09.png\" width=\"400\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kWg4z3s7f_Iu",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### 과대적합 모델의 학습 곡선 특징"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kWg4z3s7f_Iu",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 2차 다항 함수의 분포를 따르는 데이터셋에 10차 다항회귀 모델을 적용한 학습 곡선  \n",
    "    * 훈련셋에 대한 성능(빨강): 훈련셋에 대한 평균 제곱근 오차가 매우 낮음.\n",
    "    * 검증셋에 대한 성능(파랑): 검증셋에 대한 평균 제곱근 오차가 보다 높음.\n",
    "- 과대적합 모델 개선법: 훈련 데이터 추가. 하지만 일반적으로 매우 어렵거나 불가능."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-10.png\" width=\"400\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 편향 vs 분산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 편향<font size='2'>bias</font>\n",
    "\n",
    "    - 데이터셋에 대한 모델링이 틀린 경우\n",
    "    - 예를 들어 실제로는 2차원 모델인데 1차원 모델을 사용하는 경우 발생\n",
    "    - 과소적합 발생 가능성 높음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-08.png\" width=\"400\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 편향 vs 분산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 분산<font size='2'>variance</font>\n",
    "    - 모델이 훈련 데이터에 민감하게 반응하는 정도\n",
    "    - 고차 다항 회귀처럼 **자유도**<font size='2'>degree of freedom</font>가 높은 모델일 수록 분산이 커짐\n",
    "        - 모델의 자유도: 모델이 찾아야 하는 파라미터의 개수\n",
    "    - 과대적합 발생 가능성 높음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-08.png\" width=\"400\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 편향과 분산의 트레이드 오프"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 복잡한 모델일 수록 편향을 줄고 분산은 커짐."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 단순한 모델일 수록 편향은 커지고 분산은 줄어듦"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 모델 일반화 오차"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 훈련 후에 새로운 데이터 대한 예측에서 발생하는 오차.\n",
    "\n",
    "- 모델의 일반화 성능은 일반화 오차가 낮을수록 높음.\n",
    "\n",
    "- 오차 발생 원인\n",
    "    - 편향\n",
    "    - 분산\n",
    "    - 줄일 수 없는 오차: 데이터 자체가 갖고 있는 잡음(noise) 때문에 발생하는 어쩔 수 없는 오차\n",
    "\n",
    "- 결론: 모델의 편향 또는 분산 둘 중 하나에 집중하면 모델 성능을 향상시킬 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4.5. 모델 규제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 자유도와 규제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* **자유도**<font size='2'>degree of freedom</font>: 학습 모델 결정에 영향을 주는 요소(특성)들의 수\n",
    "    * 선형 회귀: 특성 수\n",
    "    * 다항 회귀: 특성 수 + 차수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* **규제**<font size='2'>regularization</font>: 가중치의 영향력을 줄이는 방향으로 모델의 자유도 제한"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 선형 회귀 모델 규제 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 릿지 회귀: 가중치의 절대값을 최대한 작게 유지. 모델의 분산을 줄임. 단 편향은 커짐."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 라쏘 회귀: 중요하지 않은 특성의 가중치를 0으로 만듦. 자유도가 줄어들어 모델의 분산이 줄어듦. 단, 편향은 커짐."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 엘라스틱 넷: 릿지 회귀와 라쏘 회귀 혼합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 릿지 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 비용함수\n",
    "\n",
    "$$J(\\theta) = \\textrm{MSE}(\\theta) + \\frac{\\alpha}{m_b} \\sum_{i=1}^{n}\\theta_i^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $m_b$: 배치 크기(하이퍼파라미터)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* $\\alpha$(알파): 규제 강도(하이퍼파라미터).\n",
    "    - $\\alpha=0$: 규제 없음\n",
    "    - $\\alpha$ 값을 크게 잡으면 가중치($\\theta_i$)의 절대값은 보다 0에 가깝워지도록 유도됨. \n",
    "        즉, 가중치의 역할이 줄어듦."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 편향($\\theta_0$): 제하지 않음. 규제해선 않됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 주의사항: 특성 스케일링 전처리를 해야 규제 모델의 성능이 좋아짐."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 릿지 회귀의 비용 함수 해석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 비용 함수의 $J(\\theta)$ 전역 최솟값: $\\sum_{i=1}^{n}\\theta_i^2$ 값이 최대한 작은 지점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- $\\theta_i$의 절대값을 가급적 0에 가깝게하는 방향으로 경사하강법이 작동"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 이렇게 하면 자연스럽게 모델의 분산도 작아짐. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 즉, 입력값이 조금 변하더라도 예측값이 변하는 정도가 약해짐."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 예측값 $\\hat y$를 계산할 때 $\\theta_i$가 미치는 영향이 작아지기 때문임.\n",
    "\n",
    "$$\\hat y = \\theta_0 + x_1 \\cdot \\theta_1 + \\cdots + x_n \\cdot \\theta_{n}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 릿지 규제를 적용한 6 가지 경우: 분산 줄고 편향 늘어남.\n",
    "\n",
    "    - 왼편: 선형 회귀 모델에 세 개의 $\\alpha$ 값 적용.\n",
    "    - 오른편: 10차 다항 회귀 모델에 세 개의 $\\alpha$ 값 적용."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/ridge01.png\" width=\"600\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 라쏘 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 비용함수\n",
    "\n",
    "$$J(\\theta) = \\textrm{MSE}(\\theta) + 2\\alpha \\, \\sum_{i=1}^{n}\\mid\\theta_i\\mid$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* $\\alpha$(알파): 규제 강도 지정.\n",
    "    $\\alpha=0$이면 규제가 전혀 없는 기본 선형 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 덜 중요한 특성을 무시하기 위해 해당 특성의 가중치 $\\mid\\theta_i\\mid$를 보다 빠르게 0에 수렴하도록 유도.\n",
    "    또한 기본적으로 $\\mid \\theta_i \\mid$ 가 가능하면 작게 움직이도록 유도."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* $\\theta_0$은 규제하지 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 라쏘 회귀의 비용 함수 해석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 비용 함수의 $J(\\theta)$ 전역 최솟값: $\\sum_{i=1}^{n}\\mid\\theta_i\\mid$ 값이 최대한 작은 지점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 별로 중요하지 않은 특성에 대해 $\\theta_i$가 0에 빠르게 수렴하도록 훈련 중에 유도됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이유: $\\mid \\theta_i \\mid$ 의 미분값이 1또는 -1 이기에 $\\theta_i$가 0이 아닌 이상\n",
    "    비용 함수의 그레이디언트의 크기가 0에 가까워 지기가 상대적으로 어렵기 때문"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 경사하강법을 반복적으로 적용하는 훈련 과정동안 중요하지 않은 특성의 가중치를 빠르게 0으로 수렴하게 만듦."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 대신 중요한 특성의 가중치를 결정하는 데에 보다 집중"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "라쏘 규제를 적용한 6 가지의 경우: 분산 줄고 편향 늘어남.\n",
    "\n",
    "- 왼편: 선형 회귀 모델에 세 개의 $\\alpha$ 값 적용.\n",
    "- 오른편: 10차 다항 회귀 모델에 세 개의 $\\alpha$ 값 적용."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/lasso01.png\" width=\"600\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 엘라스틱 넷 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 비용함수\n",
    "\n",
    "$$\n",
    "J(\\theta) = \n",
    "\\textrm{MSE}(\\theta) + \n",
    "r\\cdot \\bigg (2 \\alpha \\, \\sum_{i=1}^{n}\\mid\\theta_i\\mid \\bigg) + \n",
    "(1-r)\\cdot \\bigg (\\frac{\\alpha}{m_b}\\, \\sum_{i=1}^{n}\\theta_i^2 \\bigg )\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 릿지 회귀와 라쏘 회귀를 절충한 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 혼합 비율 $r$을 이용하여 릿지 규제와 라쏘 규제를 적절하게 조절"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 규제 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 대부분의 경우 약간이라도 규제 사용 추천"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 유용한 속성이 많지 않다고 판단되는 경우 \n",
    "    * 라쏘 규제나 엘라스틱 넷 활용 추천\n",
    "    * 불필요한 속성의 가중치를 0으로 만들기 때문"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 일반적으로 엘라스틱 넷을 보다 많이 추천"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 조기 종료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델이 훈련 중에 훈련셋에 너무 과하게 적응하지 못하도록 하는 가장 일반적인 규제 기법\n",
    "\n",
    "* 에포크가 남아있다 하더라도 검증셋 대한 비용함수의 값이 줄어 들다가 다시 커지는 순간 훈련 종료\n",
    "\n",
    "* 검증셋에 대한 비용 함수의 곡선이 진동이 발생할 있기에\n",
    "    검증 손실이 한동안 최솟값보다 높게 유지될 때 훈련 멈추고 기억해둔 최적의 모델 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-11.png\" width=\"400\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 확률적 경사하강법과 조기 종료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 코드는 `SGDRegressor` 모델에 조기 종료를 지정한다.\n",
    "\n",
    "- `penalty='elasticnet'`: 엘라스틱 넷 회귀 적용\n",
    "- `alpha=0.1`: 규제 강도\n",
    "- `l1_ratio=0.5`: 라쏘 규제 비율\n",
    "- `early_stopping=True`: 조기 종료 실행. 훈련셋의 일부를 검증셋으로 활용.\n",
    "- `max_iter=1000`: 최대 훈련 에포크\n",
    "- `tol=1e-3`: 훈련 점수 또는 검증 점수가 지정된 값 이하로 최대 `n_iter_no_change` 에포크 동안 변하지 않으면 조기 종료 실행\n",
    "- `n_iter_no_change=5`: 훈련 점수 또는 검증 점수가 지정된 에포크 동안 얼마나 변하는지 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "sgd_reg = SGDRegressor(penalty='elasticnet', alpha=0.1, l1_ratio=0.5,\n",
    "                        eta0=0.002, random_state=42,\n",
    "                        early_stopping=True,\n",
    "                        max_iter=1000, tol=1e-3, n_iter_no_change=5)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4.6 로지스틱 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 로지스틱 회귀와 소프트맥스 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 회귀 모델을 분류 모델로 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 이진 분류: 로지스틱 회귀 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 다중 클래스 분류: 소프트맥스 회귀 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 확률 계산: 시그모이드 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 시그모이드 함수 활용\n",
    "\n",
    "$$\\sigma(t) = \\frac{1}{1 + e^{-t}}$$\n",
    "\n",
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-12.png\" width=\"500\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 로지스틱 회귀 모델에서 샘플 $\\mathbf x$가 양성 클래스에 속할 확률\n",
    "\n",
    "$$\\hat p = h_\\theta (\\mathbf x)\n",
    "= \\sigma(\\theta_0 + \\theta_1\\, x_1 + \\cdots + \\theta_n\\, x_n)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 예측값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "$$\n",
    "\\hat y = \n",
    "\\begin{cases}\n",
    "0 & \\text{if}\\,\\, \\hat p < 0.5 \\\\\n",
    "1 & \\text{if}\\,\\, \\hat p \\ge 0.5\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 양성 클래스인 경우: \n",
    "\n",
    "$$\\theta_0 + \\theta_1\\, x_1 + \\cdots + \\theta_n\\, x_n \\ge 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 음성 클래스인 경우: \n",
    "\n",
    "$$\\theta_0 + \\theta_1\\, x_1 + \\cdots + \\theta_n\\, x_n < 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 비용함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 비용함수: 로그 손실<font size='2'>log loss</font> 함수 사용\n",
    "\n",
    "$$\n",
    "J(\\theta) = \n",
    "- \\frac{1}{m_b}\\, \\sum_{i=1}^{m_b}\\, \\left( y^{(i)} \\cdot \\log(\\,\\hat p^{(i)}\\,) + (1-y^{(i)}) \\cdot \\log(\\,1 - \\hat p^{(i)}\\,)\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 모델 훈련: 위 비용함수에 대해 경사 하강법 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 로그 손실 함수 이해"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 틀린 예측을 하면 손실값이 무한이 커짐\n",
    "- 아래 왼쪽 그림: 샘플의 레이블이 1(양성)인데 예측 확률($\\hat p$)이 0에 가까운 경우 로그 손실이 매우 클 수 있음\n",
    "- 아래 오른쪽 그림: 샘플의 레이블이 0(음성)인데 예측 확률($\\hat p$)이 1에 가까운 경우 로그 손실이 매우 클 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-12-10a.png\" width=\"500\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 붓꽃 데이터셋"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 붓꽃의 품종 분류를 로지스틱 회귀로 진행\n",
    "- 붓꽃 데이터셋의 샘플의 특성 4개: \n",
    "    - 꽃받침<font size='2'>sepal</font>의 길이와 너비, \n",
    "    - 꽃입<font size='2'>petal</font>의 길이와 너비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/datapy/master/jupyter-book//images/iris_petal-sepal.png\" width=\"400\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 붓꽃 데이터셋의 레이블"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 0: Iris-Setosa(세토사)\n",
    "* 1: Iris-Versicolor(버시컬러)\n",
    "* 2: Iris-Virginica(버지니카)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/iris01.png\" width=\"500\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 붓꽃 데이터셋 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사이킷런 자체 제공"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris(as_frame=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `Bunch` 자료형"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `load_iris()` 함수는 데이터셋을 사전 자료형과 유사한 `Bunch` 자료형으로 불러온다.\n",
    "- `Bunch` 자료형은 키를 사용한 인덱싱을 마치 클래스의 속성을 확인하는 방식으로 다룰 수 있음\n",
    "    - 예제: `iris['data']` 대시 `iris.data` 사용 가능\n",
    "- `data` 키: 4개의 특성으로 구성된 훈련셋 데이터프레임<font size='2'>DataFrame</font>\n",
    "- `target` 키: 레이블셋 시리즈<font size='2'>Series</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    ">>> iris.data.head(5)\n",
    "     sepal length (cm) sepal width (cm) petal length (cm) petal width (cm)\n",
    "0    5.1               3.5              1.4               0.2\n",
    "1    4.9               3.0              1.4               0.2\n",
    "2    4.7               3.2              1.3               0.2\n",
    "3    4.6               3.1              1.5               0.2\n",
    "4    5.0               3.6              1.4               0.2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 결정 경계: 꽃잎의 너비 기준 Iris-Virginica 여부 판정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "X = iris.data[[\"petal width (cm)\"]].values \n",
    "y = iris.target_names[iris.target] == 'virginica'\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-14.png\" width=\"500\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 결정 경계: 꽃잎의 너비, 길이 기준 Iris-Virginica 여부 판정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "X = iris.data[[\"petal length (cm)\", \"petal width (cm)\"]].values\n",
    "y = iris.target_names[iris.target] == 'virginica'            \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "log_reg = LogisticRegression(C=2, random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-15.png\" width=\"500\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 로지스틱 회귀 규제하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 하이퍼파라미터 `penalty`와 `C` 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* `penalty`\n",
    "    * `l1`, `l2`, `elasticnet` 세 개중에 하나 사용.\n",
    "    * 기본은 `l2`, 즉, $\\ell_2$ 규제를 사용하는 릿지 규제.\n",
    "    * `elasticnet`을 선택한 경우 `l1_ration` 옵션 값을 함께 지정."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* `C`\n",
    "    * 릿지 또는 라쏘 규제 정도를 지정하는 $\\alpha$의 역수에 해당. \n",
    "    * 따라서 0에 가까울 수록 강한 규제 의미."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 소프트맥스(softmax) 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 로지스틱 회귀 모델을 일반화하여 다중 클래스 분류를 지원하도록 한 회귀 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* **다항 로지스틱 회귀** 라고도 불림"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 주의사항: 소프트맥스 회귀는 다중 출력 분류 지원 못함. \n",
    "    예를 들어, 하나의 사진에서 여러 사람의 얼굴 인식 불가능."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 소프트맥스 회귀 학습 아이디어"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 샘플 $\\mathbf x = [x_1, \\dots, x_n]$가 주어졌을 때 각각의 분류 클래스 $k$ 에 대한 점수 $s_k(\\mathbf x)$ 계산.\n",
    "    즉, `k*(n+1)` 개의 파라미터를 학습시켜야 함.\n",
    "\n",
    "$$\n",
    "s_k(\\mathbf x) = \\theta_0^{(k)} + \\theta_1^{(k)}\\, x_1 + \\cdots + \\theta_n^{(k)}\\, x_n\n",
    "= [1, x_1, \\dots, x_n]\\, \n",
    "\\begin{bmatrix}\n",
    "\\theta_0^{(k)}\\\\\n",
    "\\theta_1^{(k)} \\\\\n",
    "\\vdots \\\\\n",
    "\\theta_n^{(k)}\n",
    "\\end{bmatrix}\n",
    "$$    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 가중치 어레이 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 편향과 가중치들의 2차원 어레이: $n=4$, 클래스 종류는 $3$개인 경우 \n",
    "\n",
    "$$\n",
    "\\Theta = \n",
    "\\begin{bmatrix}\n",
    "\\theta_0^{(0)} & \\theta_0^{(1)} & \\theta_0^{(2)} \\\\\n",
    "\\theta_1^{(0)} & \\theta_1^{(1)} & \\theta_1^{(2)} \\\\\n",
    "\\theta_2^{(0)} & \\theta_2^{(1)} & \\theta_2^{(2)} \\\\\n",
    "\\theta_3^{(0)} & \\theta_3^{(1)} & \\theta_3^{(2)} \\\\\n",
    "\\theta_4^{(0)} & \\theta_4^{(1)} & \\theta_4^{(2)} \n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 소프트맥스 함수: $\\sigma()$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $K$: 클래스(레이블)의 개수\n",
    "- $\\mathbf{s}(\\mathbf{x}) = [s_1(\\mathbf{x}), \\dots, s_K(\\mathbf{x})]$\n",
    "- $\\sigma()$ 함수: 소프트맥스 확률값 계산 함수. 각 클래스별 확률 예측값으로 구성된 어레이 생성."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "$$\n",
    "\\hat p_k \n",
    "= \\sigma(\\mathbf{s}(\\mathbf{x}))[k]\n",
    "= \\frac{\\exp(s_k(\\mathbf x))}{\\sum_{j=1}^{K}\\exp(s_j(\\mathbf x))}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat y = \n",
    "\\mathrm{np.argmax}(\\sigma(\\mathbf{s}(\\mathbf{x})))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 소프트맥스 회귀 모델 행렬 연산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모든 샘플에 대한 확률 예측값\n",
    "\n",
    "$$\n",
    "\\sigma(\\mathbf{s}(\\mathbf{X})) = \\sigma(\\mathbf{X} \\, \\Theta)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모든 샘플에 대한 최종 예측 레이블\n",
    "\n",
    "$$\n",
    "\\hat{\\mathbf{y}} = \\mathrm{np.argmax}(\\sigma(\\mathbf{X} \\, \\Theta), \\mathrm{axis}=1)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 소프트맥스 회귀의 비용함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 아래 비용 함수에 대해 경사 하강법을 적용하여 최적의 가중치 벡터 $\\theta_k^{(i)}$ 학습\n",
    "    * $K=2$이면 로지스틱 회귀의 로그 손실 함수와 정확하게 일치."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 비용함수: 크로스 엔트로피 비용 함수 사용\n",
    "\n",
    "$$\n",
    "J(\\Theta) = \n",
    "- \\frac{1}{m}\\, \\sum_{i=1}^{m}\\sum_{k=1}^{K} y^{(i)}_k\\, \\log(\\hat{p}_k^{(i)})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 클래스 $k$에 대한 그레이디언트 벡터\n",
    "\n",
    "$$\n",
    "\\nabla_{\\Theta}(k) J(\\Theta) = \n",
    "\\frac{1}{m}\\, \\sum_{i=1}^{m} \\left( \\hat{p}_k^{(i)} - y^{(i)}_k \\right)\\, \\mathbf{x}^{(i)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 다중 클래스 분류 예제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 사이킷런의 `LogisticRegression` 예측기 활용\n",
    "    * `solver=lbfgs`: 기본값이며 다중 클래스 분류에서 자동으로 소프트맥스 사용."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "X = iris.data[[\"petal length (cm)\", \"petal width (cm)\"]].values\n",
    "y = iris[\"target\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "softmax_reg = LogisticRegression(C=30, random_state=42) # 조금 약한 alpha 규제\n",
    "softmax_reg.fit(X_train, y_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 붓꽃 꽃잎의 너비와 길이를 기준으로 품종 분류\n",
    "    * 결정경계: 배경색으로 구분\n",
    "    * 곡선: 버시컬러 품종에 속할 확률"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-16.png\" width=\"500\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 로지스틱 회귀와 일대다 방식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `LogisticRegression` 모델:  `multi_clas=ovr` 옵션 사용\n",
    "- 소프트맥스 회귀 대신에 로지스틱 회귀를 일대다 방식과 혼합해서 다중 클래스 분류를 진행\n",
    "\n",
    "```python\n",
    "softmax_reg = LogisticRegression(C=30, multi_class='ovr', random_state=42)\n",
    "softmax_reg.fit(X_train, y_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-16a.png\" width=\"500\"/></div>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [],
   "name": "핸즈온머신러닝_4장.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
