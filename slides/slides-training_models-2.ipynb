{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 4장 모델 훈련 (2부)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mt1fZDkqcCSM",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4.4. 학습 곡선"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 과소적합/과대적합 판정\n",
    "\n",
    "* 예제: 선형 모델, 2차 다항 회귀 모델, 300차 다항 회귀 모델 비교\n",
    "\n",
    "* 다항 회귀 모델의 차수에 따라 훈련된 모델이 훈련셋에 과소 또는 과대 적합할 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-08.png\" width=\"600\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 교차 검증 vs. 학습 곡선"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 성능 평가는 보통 다음 두 가지 방식을 따른다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 교차 검증(2장)\n",
    "    * 과소적합: 훈련셋에 대한 성능 평가와 교차 검증 점수 모두 낮은 경우\n",
    "    * 과대적합: 훈련셋에 대한 성능 평가는 우수하지만 교차 검증 점수가 낮은 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 학습 곡선<font size='2'>learning curve</font>\n",
    "    * 훈련셋와 검증셋에 대한 모델 성능을 비교하는 그래프\n",
    "        - x-축: 훈련셋 크기. 훈련셋의 크기를 10%에서부터 출발해서 점차 키워 나가면서 모델 성능 평가\n",
    "        - y-축: 훈련셋 크기에 따른 모델 성능. 회귀 모델의 경우 일반적으로 RMSE 사용.\n",
    "    * 학습 곡선의 모양에 따라 과소적합/과대적합 판정 가능\n",
    "    * `sklearn.model_selection` 모듈의 `learning_curve()` 함수를 이용해서 쉽게 시각화 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kWg4z3s7f_Iu",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 과소적합 모델의 학습 곡선 특징"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2차 다항 함수의 분포를 따르는 데이터셋에 `LinearRegression` 모델을 적용한 학습 곡선\n",
    "\n",
    "    * 훈련셋에 대한 성능(빨강)\n",
    "        * 훈련셋가 커지면서 RMSE(평균 제곱근 오차)가 커짐\n",
    "        * 훈련셋가 어느 정도 커지면 더 이상 RMSE가 변하지 않음\n",
    "\n",
    "    * 검증셋에 대한 성능(파랑)\n",
    "        * 검증셋에 대한 성능이 훈련셋에 대한 성능과 거의 비슷해짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-09.png\" width=\"600\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kWg4z3s7f_Iu",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### 과대적합 모델의 학습 곡선 특징"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kWg4z3s7f_Iu",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 2차 다항 함수의 분포를 따르는 데이터셋에 10차 다항회귀 모델을 적용한 학습 곡선\n",
    "    \n",
    "    * 훈련셋에 대한 성능(빨강): 훈련 데이터에 대한 평균 제곱근 오차가 매우 낮음.\n",
    "    * 검증셋에 대한 성능(파랑): 훈련 데이터에 대한 성능과 차이가 크게 벌어짐.\n",
    "- 과대적합 모델 개선법: 훈련 데이터 추가. 하지만 일반적으로 어렵거나 불가능."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-10.png\" width=\"600\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 편향 vs 분산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 편향<font size='2'>bias</font>\n",
    "\n",
    "    - 데이터셋에 대한 모델링이 틀린 경우\n",
    "    - 예를 들어 실제로는 2차원 모델인데 1차원 모델을 사용하는 경우 발생\n",
    "    - 과소적합 발생 가능성 높음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 분산<font size='2'>variance</font>\n",
    "    - 모델이 훈련 데이터에 민감하게 반응하는 정도\n",
    "    - 고차 다항 회귀 모델일 수록 분산이 커짐\n",
    "    - 과대적합 발생 가능성 높음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 편향과 분산의 트레이드 오프\n",
    "    - 복잡한 모델일 수록 편향을 줄고 분산은 커짐.\n",
    "    - 단순한 모델일 수록 편향은 늘고 분산은 줄어듦"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 모델 일반화 오차"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 훈련 후에 새로운 데이터 대한 예측에서 발생하는 오차.\n",
    "\n",
    "- 모델의 일반화 성능은 일반화 오차가 낮을수록 높음.\n",
    "\n",
    "- 오차의 종류\n",
    "    - 편향\n",
    "    - 분산\n",
    "    - 줄일 수 없는 오차: 데이터 자체가 갖고 있는 잡음(noise) 때문에 발생하는 어쩔 수 없는 오차\n",
    "\n",
    "- 결론: 일반화 오차를 줄이기 위해 편향 또는 분산 둘 중에 하나에 집중해야 함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-08.png\" width=\"600\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4.5. 모델 규제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 자유도와 규제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* **자유도**<font size='2'>degree of freedom</font>: 학습 모델 결정에 영향을 주는 요소(특성)들의 수\n",
    "    * 선형 회귀: 특성 수\n",
    "    * 다항 회귀: 특성 수 + 차수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 규제<font size='2'>regularization</font>: 자유도 제한\n",
    "    * 선형 회귀 모델 규제: 가중치 역할 제한\n",
    "    * 다항 회귀 모델 규제: 차수 줄이기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 선형 회귀 모델 규제 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 릿지 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 라쏘 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 엘라스틱 넷"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 릿지 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 비용함수\n",
    "\n",
    "$$J(\\theta) = \\textrm{MSE}(\\theta) + \\frac{\\alpha}{m_b} \\sum_{i=1}^{n}\\theta_i^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $m_b$: 배치 크기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* $\\alpha$(알파): 규제 강도 지정. \n",
    "    - $\\alpha=0$이면 규제가 전혀 없는 기본 선형 회귀\n",
    "\n",
    "    * $\\alpha$가 커질 수록 가중치의 역할이 줄어듦. \n",
    "        비용을 줄이기 위해 가중치를 작게 유지하는 방향으로 학습.\n",
    "        따라서 모델의 분산 정도가 약해짐."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* $\\theta_0$은 규제하지 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 주의사항: 특성 스케일링 전처리를 해야 규제 모델의 성능이 좋아짐."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 라쏘 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 비용함수\n",
    "\n",
    "$$J(\\theta) = \\textrm{MSE}(\\theta) + 2\\alpha \\, \\sum_{i=1}^{n}\\mid\\theta_i\\mid$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* $\\alpha$(알파): 규제 강도 지정.\n",
    "    $\\alpha=0$이면 규제가 전혀 없는 기본 선형 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 덜 중요한 특성을 무시하기 위해 해당 특성의 가중치 $\\mid\\theta_i\\mid$를 보다 빠르게 0에 수렴하도록 유도.\n",
    "    또한 기본적으로 $\\mid \\theta_i \\mid$ 가 가능하면 작게 움직이도록 유도."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* $\\theta_0$은 규제하지 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 엘라스틱 넷 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 비용함수\n",
    "\n",
    "$$\n",
    "J(\\theta) = \n",
    "\\textrm{MSE}(\\theta) + \n",
    "r\\cdot \\bigg (2 \\alpha \\, \\sum_{i=1}^{n}\\mid\\theta_i\\mid \\bigg) + \n",
    "(1-r)\\cdot \\bigg (\\frac{\\alpha}{m_b}\\, \\sum_{i=1}^{n}\\theta_i^2 \\bigg )\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 릿지 회귀와 라쏘 회귀를 절충한 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 혼합 비율 $r$을 이용하여 릿지 규제와 라쏘 규제를 적절하게 조절"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 규제 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 대부분의 경우 약간이라도 규제 사용 추천"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 릿지 규제가 기본"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 유용한 속성이 많지 않다고 판단되는 경우 \n",
    "    * 라쏘 규제나 엘라스틱 넷 활용 추천\n",
    "    * 불필요한 속성의 가중치를 0으로 만들기 때문"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 특성 수가 훈련 샘플 수보다 많거나 특성 몇 개가 상호 강하게 연관되어 있는 경우엔 엘라스틱 넷 추천"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 조기 종료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델이 훈련 중에 훈련셋에 너무 과하게 적응하지 못하도록 하는 가장 일반적인 규제 기법\n",
    "\n",
    "* 에포크가 남아있다 하더라도 검증셋 대한 비용함수의 값이 줄어 들다가 다시 커지는 순간 훈련 종료\n",
    "\n",
    "* 검증셋에 대한 비용 함수의 곡선이 진동이 발생할 있기에\n",
    "    검증 손실이 한동안 최솟값보다 높게 유지될 때 훈련 멈추고 기억해둔 최적의 모델 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-11.png\" width=\"600\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4.6 로지스틱 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 회귀 모델을 분류 모델로 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 이진 분류: 로지스틱 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 다중 클래스 분류: 소프트맥스 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 확률 추정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 시그모이드 함수\n",
    "\n",
    "$$\\sigma(t) = \\frac{1}{1 + e^{-t}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-12.png\" width=\"600\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 로지스틱 회귀 모델에서 샘플 $\\mathbf x$가 양성 클래스에 속할 확률\n",
    "\n",
    "$$\\hat p = h_\\theta (\\mathbf x)\n",
    "= \\sigma(\\theta_0 + \\theta_1\\, x_1 + \\cdots + \\theta_n\\, x_n)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 예측값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$$\n",
    "\\hat y = \n",
    "\\begin{cases}\n",
    "0 & \\text{if}\\,\\, \\hat p < 0.5 \\\\\n",
    "1 & \\text{if}\\,\\, \\hat p \\ge 0.5\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 양성 클래스인 경우: \n",
    "\n",
    "$$\\theta_0 + \\theta_1\\, x_1 + \\cdots + \\theta_n\\, x_n \\ge 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 음성 클래스인 경우: \n",
    "\n",
    "$$\\theta_0 + \\theta_1\\, x_1 + \\cdots + \\theta_n\\, x_n < 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 비용함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 비용함수: 로그 손실<font size='2'>log loss</font> 함수 사용\n",
    "\n",
    "$$\n",
    "J(\\theta) = \n",
    "- \\frac{1}{m_b}\\, \\sum_{i=1}^{m_b}\\, \\left( y^{(i)} \\cdot \\log(\\,\\hat p^{(i)}\\,) + (1-y^{(i)}) \\cdot \\log(\\,1 - \\hat p^{(i)}\\,)\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 모델 훈련: 위 비용함수에 대해 경사 하강법 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 로그 손실 함수 이해"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 틀린 예측을 하면 손실값이 무한이 커짐\n",
    "- 아래 왼쪽 그림: 샘플의 레이블이 1(양성)인데 예측 확률($\\hat p$)이 0에 가까운 경우 로그 손실이 매우 클 수 있음\n",
    "- 아래 오른쪽 그림: 샘플의 레이블이 0(음성)인데 예측 확률($\\hat p$)이 1에 가까운 경우 로그 손실이 매우 클 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-12-10a.png\" width=\"600\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 붓꽃 데이터셋"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "붓꽃의 품종 분류를 로지스틱 회귀로 진행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 결정 경계"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 예제: 붓꽃 데이터셋"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 꽃받침(sepal)과 꽃입(petal)과 관련된 4개의 특성 사용\n",
    "    * 꽃받침 길이\n",
    "    * 꽃받침 너비\n",
    "    * 꽃잎 길이\n",
    "    * 꽃잎 너비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 타깃: 세 개의 품종\n",
    "    * 0: Iris-Setosa(세토사)\n",
    "    * 1: Iris-Versicolor(버시컬러)\n",
    "    * 2: Iris-Virginica(버지니카)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 꽃잎의 너비를 기준으로 Iris-Virginica 여부 판정하기\n",
    "\n",
    "* 결정경계: 약 1.6cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-14.png\" width=\"700\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 꽃잎의 너비와 길이를 기준으로 Iris-Virginica 여부 판정하기\n",
    "\n",
    "* 결정경계: 검정 점선"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-15.png\" width=\"700\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 로지스틱 회귀 규제하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 하이퍼파라미터 `penalty`와 `C` 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* `penalty`\n",
    "    * `l1`, `l2`, `elasticnet` 세 개중에 하나 사용.\n",
    "    * 기본은 `l2`, 즉, $\\ell_2$ 규제를 사용하는 릿지 규제.\n",
    "    * `elasticnet`을 선택한 경우 `l1_ration` 옵션 값을 함께 지정."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* `C`\n",
    "    * 릿지 또는 라쏘 규제 정도를 지정하는 $\\alpha$의 역수에 해당. \n",
    "    * 따라서 0에 가까울 수록 강한 규제 의미."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4.6.4 소프트맥스(softmax) 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 로지스틱 회귀 모델을 일반화하여 다중 클래스 분류를 지원하도록 한 회귀 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* **다항 로지스틱 회귀** 라고도 불림"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 주의사항: 소프트맥스 회귀는 다중 출력 분류 지원 못함. \n",
    "    예를 들어, 하나의 사진에서 여러 사람의 얼굴 인식 불가능."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 소프트맥스 회귀 학습 아이디어"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 샘플 $\\mathbf x$가 주어졌을 때 각각의 분류 클래스 $k$ 에 대한 점수 $s_k(\\mathbf x)$ 계산.\n",
    "    즉, `k*(n+1)` 개의 파라미터를 학습시켜야 함.\n",
    "\n",
    "$$\n",
    "s_k(\\mathbf x) = \\theta_0^{(k)} + \\theta_1^{(k)}\\, x_1 + \\cdots + \\theta_n^{(k)}\\, x_n\n",
    "$$    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* __소프트맥스 함수__를 이용하여 각 클래스 $k$에 속할 확률 $\\hat p_k$ 계산\n",
    "\n",
    "$$\n",
    "\\hat p_k = \n",
    "\\frac{\\exp(s_k(\\mathbf x))}{\\sum_{j=1}^{K}\\exp(s_j(\\mathbf x))}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 추정 확률이 가장 높은 클래스 선택\n",
    "\n",
    "$$\n",
    "\\hat y = \n",
    "\\mathrm{argmax}_k s_k(\\mathbf x)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 소프트맥스 회귀 비용함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 각 분류 클래스 $k$에 대한 적절한 가중치 벡터 $\\theta_k$를 학습해 나가야 함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 비용함수: 크로스 엔트로피 비용 함수 사용\n",
    "\n",
    "$$\n",
    "J(\\Theta) = \n",
    "- \\frac{1}{m}\\, \\sum_{i=1}^{m}\\sum_{k=1}^{K} y^{(i)}_k\\, \\log(\\hat{p}_k^{(i)})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 위 비용함수에 대해 경사 하강법 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* $K=2$이면 로지스틱 회귀의 로그 손실 함수와 정확하게 일치."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 주어진 샘플의 타깃 클래스를 제대로 예측할 경우 높은 확률값 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 크로스 엔트로피 개념은 정보 이론에서 유래함. 자세한 설명은 생략."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 다중 클래스 분류 예제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 사이킷런의 `LogisticRegression` 예측기 활용\n",
    "    * `multi_class=multinomial`로 지정\n",
    "    * `solver=lbfgs`: 다중 클래스 분류 사용할 때 반드시 지정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 붓꽃 꽃잎의 너비와 길이를 기준으로 품종 분류\n",
    "    * 결정경계: 배경색으로 구분\n",
    "    * 곡선: Iris-Versicolor 클래스에 속할 확률"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-16.png\" width=\"700\"/></div>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [],
   "name": "핸즈온머신러닝_4장.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
