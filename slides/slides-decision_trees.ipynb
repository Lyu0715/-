{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WUDunXR-3YKu",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 6장 결정트리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 주요내용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hBxgwiZb3iHR",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 결정트리 훈련과 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hBxgwiZb3iHR",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- CART 알고리즘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 지니 불순도 vs. 엔트로피"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 결정트리 규제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hBxgwiZb3iHR",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 회귀 결정트리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 결정트리 단점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xjQC0LJV38v0",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 6.1 결정트리 훈련과 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xjQC0LJV38v0",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 결정트리 훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xjQC0LJV38v0",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 결정트리 방식의 최대 장점: 데이터 전처리 일반적으로 불필요. 필요한 경우도 존재.\n",
    "* 사이킷런의 `DecisionTreeClassifier` 모델 활용\n",
    "* 붓꽃 데이터 활용. 꽃잎의 길이와 너비 기준으로 분류.\n",
    "* `max_depth=2`: 결정트리의 최대 깊이 지정. \n",
    "    여기서는 최대 2번의 데이터셋 분할 허용. 기본값은 `None`이며 무제한 데이터셋 분할 허용."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xjQC0LJV38v0",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "```python\n",
    "iris = load_iris(as_frame=True)\n",
    "X_iris = iris.data[[\"petal length (cm)\", \"petal width (cm)\"]].values\n",
    "y_iris = iris.target\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(max_depth=2, random_state=42)\n",
    "tree_clf.fit(X_iris, y_iris)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uQyfP6CW4zPh",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 결정트리 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uQyfP6CW4zPh",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 사이킷런의 `export_graphviz()` 함수 활용\n",
    "* pdf, png 등 많은 종류의 파일로 변환 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch06/homl06-01.png\" width=\"400\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YkzEuDkB6VoY",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 결정트리 노드의 속성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YkzEuDkB6VoY",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* `gini`: 노드의 지니 불순도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YkzEuDkB6VoY",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* `samples`: 노드에 속하는 샘플수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YkzEuDkB6VoY",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* `value`: 각각의 범주(클래스)에 속하면서 노드에 포함된 샘플 수. 타깃 정보 활용."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YkzEuDkB6VoY",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* `class`: 가장 높은 비율을 차지하는 범주. 비율이 동일한 경우 낮은 인덱스의 범주 선택."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YgctkyUP5LUL",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 트리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "트리<font size='2'>rooted tree</font>는 아래 성질을 만족하는\n",
    "노드<font size='2'>node</font>와 이음선<font size='2'>edge</font>들로 구성됨.\n",
    "\n",
    "- 루트로 사용되는 하나의 노드가 있음.\n",
    "- 루트를 제외한 모든 노드는 부모 노드로부터 오는 진입 이음선으로 연결됨.\n",
    "- 루트로부터 임의의 노트로 연결되는 경로가 유일하게 존재함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch06/treedef1.png\" width=\"300\"/></div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YgctkyUP5LUL",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 트리 구성 요소"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 루트<font size='2'>root</font> 노드: 맨 상단에 위치한 노드. 부모 노드를 갖지 않음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 잎<font size='2'>leaf</font> 노드: 더 이상의 가지분할이 발생하지 않는 노드. 자식 노드를 갖지 않음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 노드의 인덱스"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "노드의 인덱스는 깊이 우선 탐색<font size='2'>depth-first-search</font>(DFS) 방식으로 이루워짐.\n",
    "\n",
    "- 루트 노드에서 시작해서 갈 수 있는 한 가장 왼쪽 자식 노드로 탐색 진행\n",
    "\n",
    "- 잎 노드에 다달한 경우 탐색 대상이 될 수 있는 자식 노드를 갖는 가장 가까운 조상 노드로 이동해서 깊이 우선 탐색 진행. \n",
    "    단, 한 번 탐색한 자식 노드는 무시."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<p><div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch06/depth-first-search.gif\" width=\"500\"/></div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 지니 불순도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $G_i$: $i$-번째 노드의 지니 불순도\n",
    "\n",
    "$$G_i = 1 - \\sum_{k=0}^{K-1} (p_{i,k})^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $p_{i,k}$는 $i$ 번째 노드에 있는 훈련 샘플 중 범주 $k$에 속한 샘플의 비율. $K$는 범주의 개수."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 예제: 깊이 2의 왼편 노드 $G_3$ 의 지니 불순도\n",
    "\n",
    "$$G_4 = 1 - (0/54)^2 - (49/54)^2 - (5/54)^2 = 0.168$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 예제: 깊이 1의 왼편 노드 $G_1$ 의 지니 불순도. 세토사 품종으로만 구성되었음.\n",
    "\n",
    "$$G_1 = 1 - (55/55)^2 - (0/55)^2 - (0/55)^2 = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 범주 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dYcae39N5kQ2",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 예제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 꽃잎 길이와 너비: 각각 5cm, 1.5cm\n",
    "\n",
    "* 데이터가 주어지면 루트에서 시작\n",
    "\n",
    "* 분할 1단계: 꽃잎 길이가 2.45cm 이하가 아니기에 오른편으로 이동.\n",
    "\n",
    "* 분할 2단계: 꽃잎 너비가 1.75cm 이하이기에 왼편으로 이동. 버시컬러로 판정."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 결정경계"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "아래 그림은 `max_depth=3`으로 지정해서 학습한 결정트리의 결졍경계를 보여줌.\n",
    "\n",
    "* 1차 분할 기준: 꽃잎 길이 2.45cm. 트리 깊이 0에서 진행됨.\n",
    "* 2차 분할 기준: 꽃잎 너비 1.75cm. 트리 깊이 1에서 진행됨.\n",
    "* 3차 분할 기준: 꽃잎 길이 4.95cm. 트리 깊이 2에서 진행됨.\n",
    "* 4차 분할 기준: 꽃잎 길이 4.85cm. 트리 깊이 2에서 진행됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch06/homl06-02a.png\" width=\"500\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch06/homl06-02c.png\" width=\"600\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 범주에 속할 확률"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YkzEuDkB6VoY",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 주어진 샘플에 대해 예측된 노드에 속한 샘플들의 범주별 비율"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YkzEuDkB6VoY",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- `max_depth=2`로 훈련된 `tree_clf` 모델은 예를 들어\n",
    "    꽃잎 길이와 너비가 각각 5cm, 1.5cm인 붓꽃을 깊이 2의 왼편 잎 노드인 $G_3$에 포함시킴.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YkzEuDkB6VoY",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- $G_3$ 노드에 포함된 샘플들의 범주별 비율: (세토사, 버시컬러, 버지니카)\n",
    "    \n",
    "$$(0/54, 49/54, 5/54) = (0, 0.907, 0.093)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YkzEuDkB6VoY",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 버시컬러에 속할 확률이 90.7%로 가장 높기에 해당 샘플은 버시컬러로 예측됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `predict_proba()` vs. `predict()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`predict_proba()` 메서드: 지정된 샘플의 범주별 추정 확률을 계산\n",
    "\n",
    "```python\n",
    ">>> tree_clf.predict_proba([[5, 1.5]]).round(3)\n",
    "array([[0.   , 0.907, 0.093]])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`predict()` 메서드: 품종 범주를 예측하며, 가장 높은 추정 확률을 갖는 품종으로 지정.\n",
    "\n",
    "```python\n",
    ">>> tree_clf.predict_proba([[5, 1.5]]).round(3)\n",
    "array([1])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`max_depth=3` 인 경우 다르게 예측됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "```python\n",
    ">>> tree_clf_deeper.predict_proba([[5, 1.5]]).round(3)\n",
    "array([[0.   , 0.333, 0.667]])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "```python\n",
    ">>> tree_clf_deeper.predict([[5, 1.5]]).round(3)\n",
    "array([2])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 6.2 CART 훈련 알고리즘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "44q4QDKU905A",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### CART(Classification and Regression Tree) 분류 알고리즘의 비용함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "44q4QDKU905A",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 각 노드에서 아래 비용함수를 최소화 하는 특성 $k$와 해당 특성의 임곗값 $t_k$를 결정해서 사용함.\n",
    "    - $m$, $m_\\text{left}$, $m_\\text{right}$: 각각 부모와 양쪽 자식 노드에 속한 샘플 수\n",
    "    - $G_\\text{left}$, $G_\\text{right}$: 두 자식 노드의 지니 불순도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "44q4QDKU905A",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "$$\n",
    "J(k, t_k) = \\frac{m_\\text{left}}{m}\\, G_\\text{left} + \\frac{m_\\text{right}}{m}\\, G_\\text{right}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "44q4QDKU905A",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* $J(k, t_k)$가 작을 수록 불순도가 낮은 두 개의 부분집합으로 분할됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "44q4QDKU905A",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* __참고__: 탐욕적 알고리즘 사용. 해당 노드를 기준으로 지니 불순도가 가장 낮은, 즉, 가장 순수한(pure) 두 개의 부분집합으로 분할함.\n",
    "    최적의 분할이란 보장은 없지만 일반적으로 적절한 성능을 보임."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "44q4QDKU905A",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 분할 과정 반복: `max_depth` 등 규제의 한계에 다다르거나 더 이상 불순도를 줄이는 분할이 불가능할 때까지 진행."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "65z6hFwC-4ds",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### CART 알고리즘의 계산 복잡도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "65z6hFwC-4ds",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 최적의 결정트리를 찾는 문제는 NP-완전(NP-complete)임."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "65z6hFwC-4ds",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 이런 문제의 시간 복잡도는 $O(\\exp(m))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "65z6hFwC-4ds",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 매우 작은 훈련셋에 대해서도 제대로 적용하기 어려움"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 결정트리 모델의 예측 시간 복잡도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "65z6hFwC-4ds",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 학습된 결정트리가 예측에 필요한 시간: $O(\\log m)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "65z6hFwC-4ds",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 훈련 샘플 수 $m$에만 의존하며 매우 빠름. \n",
    "    각 노드에서 하나의 특성만 분류기준으로 사용되기에 특성 수와 무관하기 때문임."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### CART 알고리즘의 시간 복잡도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 훈련 샘플이 크기순으로 정렬된 경우 ($n, m$은 각각 특성 개수와 샘플 개수를 나타냄):\n",
    "    * 각 노드에서 분류하는 데 걸리는 시간: $O(n\\cdot m\\cdot \\log(m))$\n",
    "    * 결정트리를 완성하는 데 걸리는 시간: $O(n\\cdot m^2\\cdot \\log(m))$ \n",
    "    * 규제가 있는 경우 좀 더 빨라짐."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "65z6hFwC-4ds",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 훈련셋의 크기가 몇 천보다 크면 정렬 자체가 오래 걸림. 가장 빠른 정렬 알고리즘의 복잡도가 $O(m\\log m)$ 정도임."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XaVDK_hy___q",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 지니 불순도 vs. 엔트로피"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- `DecisionTreeClassifier`의 `criterion=\"entropy\"` 옵션 설정: \n",
    "    - gini 불순도 대신에 샘플들의 **무질서** 정도를 측정하는 엔트로피 사용\n",
    "    - 지니 불순도를 사용할 때와 비교해서 큰 차이가 나지 않음.\n",
    "    - 엔트로피 방식이 노드를 보다 균형 잡힌 두 개의 자식 노드로 분할함.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- $i$-번 인덱스 노드의 엔트로피\n",
    "\n",
    "$$H_i = -\\sum_{\\substack{k=1\\\\p_{i,k}\\neq 0}}^{K} p_{i,k} \\log_2(p_{i,k})$$    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 두 방식의 큰 차이가 없고 지니 불순도 방식이 보다 빠르게 훈련되어 기본값으로 지정됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r69il0FtBDTZ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 규제 하이퍼파라미터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 비파라미터 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r69il0FtBDTZ",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 결정트리 모델은 데이터에 대한 어떤 가정도 하지 않음. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r69il0FtBDTZ",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 예를 들어, 노드를 분할할 수 있는 자유도<font size='2'>degree of freedom</font>에 대한 제한이 기본적으로 없음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r69il0FtBDTZ",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 이런 모델을 **비파라미터 모델**<font size='2'>nonparametric model</font>이라 함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r69il0FtBDTZ",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 규제를 가하지 않으면 과대적합 위험 매우 높음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r69il0FtBDTZ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 사이킷런  `DecisionTreeClassifier` 규제 하이퍼파라미터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r69il0FtBDTZ",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 규제 강화 방법\n",
    "    * `min_` 접두사 사용 규제: 값을 키울 것\n",
    "    * `max_` 접두사 사용 규제: 값을 감소시킬 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 하이퍼파라미터 | 기능 |\n",
    "|:---|:---|\n",
    "| `max_depth` | 결정트리의 높이 제한 |\n",
    "| `min_samples_split` | 노드 분할해 필요한 최소 샘플 개수 |\n",
    "| `min_samples_leaf` | 잎 노드에 포함된 최소 샘플 개수 |\n",
    "| `max_leaf_nodes` | 최대 잎 노드 개수 |\n",
    "| `max_features` | 분할에 사용되는 특성 개수 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r69il0FtBDTZ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 예제: 규제 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oeGK7R0rCP_I",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 예제: 초승달 데이터셋에 대한 결정트리 모델 학습\n",
    "    * 왼편: 규제 전혀 없음. 보다 정교하며 과대적합됨.\n",
    "    * 오른편: `min_samples_leaf=5`. 일반화 성능이 보다 좋음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X_moons, y_moons = make_moons(n_samples=150, noise=0.2, random_state=42)\n",
    "\n",
    "tree_clf1 = DecisionTreeClassifier(random_state=42)\n",
    "tree_clf2 = DecisionTreeClassifier(min_samples_leaf=5, random_state=42)\n",
    "tree_clf1.fit(X_moons, y_moons)\n",
    "tree_clf2.fit(X_moons, y_moons)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch06/homl06-03.png\" width=\"800\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "31HcJrG8DBbP",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 6.3 회귀 결정트리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ta34qi8vDKE1",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 사이킷런의 `DecisionTreeRegressor` 예측기 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "31HcJrG8DBbP",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 결정트리 알고리즘 아이디어를 거의 그대로 이용하여 회귀 문제에 적용 가능\n",
    "\n",
    "    ```python\n",
    "    tree_reg = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
    "    tree_reg.fit(X, y)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 예제: 잡음이 포함된 2차 함수 형태의 데이터셋"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 왼편 그림 설명\n",
    "\n",
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch06/homl06-05.png\" width=\"600\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gdPEwMOKD2Ts",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 각 노드에 포함된 속성\n",
    "  * `samples`: 해당 노드에 속한 훈련 샘플 수\n",
    "  * `value`: 해당 노드에 속한 훈련 샘플의 평균 타깃값\n",
    "  * `squared_error`: 해당 노드에 속한 훈련 샘플의 평균제곱오차(MSE)\n",
    "    * 오차 기준은 `value` 사용."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 왼편 그림 설명\n",
    "\n",
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch06/homl06-05.png\" width=\"600\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch06/homl06-04.png\" width=\"600\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Wv-PadWE4su",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 회귀용 CART 알고리즘과 비용함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "44q4QDKU905A",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 분류의 경우처럼 탐욕적으로 아래 비용함수를 최소화 하는 특성 $k$와 해당 특성의 임곗값 $t_k$을 결정함:\n",
    "    * $\\text{MSE}_\\text{node}$: 해당 노드의 평균제곱오차(MSE).\n",
    "    * $m_\\text{node}$: 해당 노드에 속하는 샘플 수\n",
    "    * $y^{(i)}$: 샘플 $i$에 대한 실제 타깃값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "44q4QDKU905A",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "J(k, t_k) &= \\frac{m_\\text{left}}{m}\\, \\text{MSE}_\\text{left} + \\frac{m_\\text{right}}{m}\\, \\text{MSE}_\\text{right} \\\\[2ex]\n",
    "\\text{MSE}_\\text{node} &= \\frac{1}{m_\\text{node}} \\sum_{i\\in \\text{node}} (\\hat y_{node} - y^{(i)})^2\\\\[1ex]\n",
    "\\hat y_\\text{node} &= \\frac{1}{m_\\text{node}} \\sum_{i\\in\\text{node}} y^{(i)}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s5CYDKUtFn3b",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 규제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s5CYDKUtFn3b",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 분류의 경우처럼 규제가 없으면 과대적합 발생할 수 있음.\n",
    "\n",
    "* 왼편: 규제가 없는 경우. 과대적합 발생\n",
    "    \n",
    "* 오른편: `min_samples_leaf=10`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch06/homl06-06.png\" width=\"600\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gppqltl-F3Rc",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 6.4 결정트리 단점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 단점 1: 훈련셋 회전 민감도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gppqltl-F3Rc",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 결정트리 알고리즘은 성능이 매우 우수하지만 기본적으로 주어진 훈련셋에 민감하게 반응함.\n",
    "\n",
    "* 결정트리는 항상 축에 수직인 분할을 사용. 따라서 조금만 회전을 가해도 결정 경계가 많이 달라짐\n",
    "\n",
    "* 예제: 오른편 그래프: 왼편 그래프를 45도 회전시킨 훈련셋 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch06/homl06-07.png\" width=\"600\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 예제: PCA() 모델 기법 적용 데이터 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PCA 기법: 데이터셋을 회전시켜서 특성들 사이의 연관성을 약화시킴\n",
    "- 예제: PCA 기법으로 회전시킨 붓꽃 데이터셋에 분류 결정트리를 훈련시킨 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "pca_pipeline = make_pipeline(StandardScaler(), PCA())\n",
    "X_iris_rotated = pca_pipeline.fit_transform(X_iris)\n",
    "tree_clf_pca = DecisionTreeClassifier(max_depth=2, random_state=42)\n",
    "tree_clf_pca.fit(X_iris_rotated, y_iris)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch06/homl06-08d.png\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8y7IjEKKGd4j",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 단점 2: 높은 분산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 훈련 데이터의 작은 변화에도 매우 민감함.\n",
    "\n",
    "* `random_state`를 지정하지 않으면서 동일한 모델을 훈련 시키면 다른 결과 나옴(아래 그래프 참고)\n",
    "\n",
    "* 많은 트리에서 만든 예측값의 평균을 활용 추천(7장 램덤포레스트 모델 참고)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch06/homl06-08e.png\"/></div>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [],
   "name": "핸즈온머신러닝_6장.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
