{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdd87f13",
   "metadata": {},
   "source": [
    "# 실습 과제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b15cd3",
   "metadata": {
    "id": "vrqhX20ses4E"
   },
   "source": [
    "## 과제 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8ec23c",
   "metadata": {
    "id": "nehAblbievOG"
   },
   "source": [
    "아래의 세 가지 변환을 전처리 과정에 추가하면 훈련된 모델의 성능이 어떻게 얼마나 달라지는지 이전 모델과 비교하라.\n",
    "\n",
    "__변환 1__\n",
    "\n",
    "중간 소득과 중간 주택 가격 사이의 상관관계 그래프에서 확인할 수 있는 수평선에 위치한 데이터를 삭제한다.\n",
    "\n",
    "__변환 2__\n",
    "\n",
    "회귀 모델 훈련에 사용되는 12개의 특성 중에 세 개는 기존 9개의 특성을 조합하여 생성하였다. 12개의 특성 중에 중간 주택 가격과의 상관계수의 절댓값이 0.2 보다 작은 특성을 삭제한다.\n",
    "\n",
    "주의사항: 특성 삭제는 훈련 세트 뿐만 아니라 테스트 세트에 대해서도 진행해야 한다. 특성이 다르면 동일한 모델을 적용할 수 없다.\n",
    "\n",
    "__변환 3__\n",
    "\n",
    "범주형 특성을 제외한 9개 특성별 히스토그램을 보면 일부 특성의 히스토그램이 좌우 비대칭이다. \n",
    "(전문 용어로 __왜도__(skewness)가 0이 아닐 때 이런 분포가 발생한다.)\n",
    "대표적으로 방의 총 개수(total_rooms), 침실 총 개수(total_bedrooms), 인구(population), 가구수(households), 중간소득(median_income) 등 다섯 개의 특성이 그렇다.\n",
    "앞서 언급된 5개 특성 또는 일부에 대해 __로그 변환__을 적용한다.\n",
    "\n",
    "**힌트**\n",
    "\n",
    "1. 언급된 세 가지 변환을 우선 하나씩 구현하고 구현 가능한 변환만 접목할 것.\n",
    "1. California Housing Price Prediction 프로젝트 관련 사이트를 살펴보고 비슷하게 진행할 것.\n",
    "    - [캐글(kaggle) 참고 페이지 1](https://www.kaggle.com/khushboon/california-housing-price-prediction)\n",
    "    - [캐글(kaggle) 참고 페이지 2](https://www.kaggle.com/suprabhatsk/california-housing-prices-prediction)\n",
    "    - [캐글(kaggle) 참고 페이지 3](https://www.kaggle.com/subashdump/california-housing-price-prediction)\n",
    "1. 지정된 특성값을 갖는 데이터 샘플 삭제 요령 참고 문서\n",
    "    - [참고 1](https://www.codegrepper.com/code-examples/python/how+to+drop+specific+values+in+pandas)\n",
    "    - [참고 2](https://chrisalbon.com/python/data_wrangling/pandas_dropping_column_and_rows/)\n",
    "1. 상관관계 도표에서 수평선 위치 찾기\n",
    "    - 방식 1: 중간 주택 가격의 히스토 그램에서 50만을 제외한 45만, 35만, 28만 근처에서의 수평선의 정확한 위치를 알아내기 위해 히스토그램을 언급된 값 근처의 구간으로 제한해서 히스토그램을 그리면 확인할 수 있을 것임. 다른 보다 편한 방식은 잘 모르겠음. 히스토그램을 제한하는 방식은 앞서 언급한 참고1, 2에서 소개한 방식 활용 가능\n",
    "    - [valut_count() 메서드 활용](https://www.w3resource.com/pandas/series/series-value_counts.php)\n",
    "1. 로그 변환: 넘파이의 log() 함수를 데이터프레임에 적용. 데이터프레임의 apply() 메서드 활용.\n",
    "    - [참고 코드](https://nbviewer.jupyter.org/github/justmarkham/pandas-videos/blob/master/pandas.ipynb#30.-How-do-I-apply-a-function-to-a-pandas-Series-or-DataFrame%3F-%28video%29), \n",
    "    [참고 코드 설명 동영상](https://www.youtube.com/watch?v=P_q0tkYqvSk&list=PL5-da3qGB5ICCsgW1MxlZ0Hq8LL5U3u9y&index=30)\n",
    "    - 로그 변환 실전 활용 예제: [Housing Price Predictions Using Advanced Regression Techniques](https://github.com/atsigman/putb_nycdsa_kaggle/blob/master/kaggle_eda_version11_modeling.ipynb), `In [465]`, 즉 465번째 코드 셀(Testing if fixing Skewed Features Help) 참조"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3410b796",
   "metadata": {
    "id": "v_OAt0Qh4i9r"
   },
   "source": [
    "**참고: 로그 변환**\n",
    "\n",
    "__로그 변환__(log transformation)은 수치 데이터에 로그(log) 함수를 적용하는 변환이며, 로그 변환이 이루어진 데이터의 분포는 보다 정규 분포에 가까워진다. \n",
    "아래 그림은 왜도가 0이 아닌 분포(상단)에 로그 변환을 가했을 때 생성된 분포(하단)의 왜도가 훨씬 약화되어 정규분포에 가까워지는 것을 보여준다. \n",
    "<img src=\"https://i.stack.imgur.com/7iSYs.png\">\n",
    "\n",
    "<그림 출처: [StackExchange](https://stats.stackexchange.com/questions/107610/what-is-the-reason-the-log-transformation-is-used-with-right-skewed-distribution)>\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
